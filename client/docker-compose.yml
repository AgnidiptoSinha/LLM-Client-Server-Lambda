version: '3.8'

services:
  llm-client:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-conversational-agent
    volumes:
      - ./logs:/app/logs
      - ./conversations:/app/conversations
    environment:
      - JAVA_OPTS=-Xms512m -Xmx1024m -Dlogback.debug=true
      # For EC2 communication
      - EC2_URL=http://ec2-54-89-45-115.compute-1.amazonaws.com:8000
      # For local Ollama
      - OLLAMA_HOST=http://host.docker.internal:11434
    networks:
      - llm-network
    command: ["java", "-jar", "/app/app.jar", "Tell me about artificial intelligence"]  # Added default prompt

networks:
  llm-network:
    name: llm-network
    driver: bridge